#Use model for prediction
nb.class <- predict(nb.fit, Smarket.2005)
table(nb.class, Direction.2005)
mean(nb.class == Direction.2005)
nb.preds <- predict(nb.fit, Smarket.2005, type = "raw")
nb.preds[1:5,]
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
#Calculate the test MSE
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#Fit a quadratic and cubic model with the poly() function
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg- predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg- predict(lm.fit3, Auto))[-train]^2)
#boot package contains cv.glm()
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0,10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
#Display the test MSE for each all polynomial models
cv.error
set.seed(17)
cv.error.10 <- rep(0,10)
for(i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index){
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X,Y)) / (var(X) + var(Y) - 2*cov(X,Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = TRUE))
boot(
data = Portfolio,
statistic = alpha.fn,
R = 1000
)
#Define function (no brackets needed since it's only one line)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
#
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, TRUE))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
#Bootstrap method
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
#standard calculation
summary(
lm(mpg ~ horsepower + I(horsepower^2), Auto)
)$coef
#Preview the data
names(Hitters)
dim(Hitters)
str(Hitters)
#Find the number of missing values for Salary
sum(is.na(Hitters$Salary))
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
library(leaps)
regfit.full <- regsubsets(Salary~., Hitters)
summary(regfit.full)
regfit.full <- regsubsets(Salary~., Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
names(reg.summary)
#view the R^2 statistic
reg.summary$rsq
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col = "red", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], col = "red", cex = 2,
pch = 20)
which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(6, reg.summary$bic[6], col = "red", cex = 2,
pch = 20)
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
coef(regfit.full, 6)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . -Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
high <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, high)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(high ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
high <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, high)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(high ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(Carseats$High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(Carseats$High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(Carseats$High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
#Load package for decision trees
library(tree)
library(ISLR2)
#Load the Carseats sales dataset for analysis
attach(Carseats)
#Create new variable to classify sales as High or low
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
#Combine High variable with Carseats data
Carseats <- data.frame(Carseats, High)
#Create classification tree model to predict High with all variables except Sales
tree.carseats <- tree(High ~ . - Sales, Carseats)
#List the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate.
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
tree.carseats
plot(tree.carseats)
text(tree.carseats, pretty = 0)
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train,]
High.test <- High[-train]
tree.carseats <- tree(High ~ . - Sales, Carseats, subset = train)
tree.pred <- predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train,]
High.test <- High[-train]
tree.carseats <- tree(High ~ . - Sales, Carseats, subset = train)
tree.pred <- predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
(104+50)/200
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
High.test
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
set.seed(7)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
(97+58)/200
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston <- tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston <- tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty = 0)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston <- tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty = 0)
#Prune the tree
cv.boston <- cv.tree(tree.boston)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston <- tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty = 0)
#Prune the tree
cv.boston <- cv.tree(tree.boston)
plot(cv.boston$size, cv.boston$dev, type = "b")
prune.boston <- prune.tree(tree.boston, best = 5)
plot(prune.boston)
text(prune.boston, pretty = 0)
prune.boston <- prune.tree(tree.boston, best = 5)
plot(prune.boston)
text(prune.boston, pretty = 0)
#Use the unpruned tree (in this example) to make predictions
yhat <- predict(tree.boston, newdata = Boston[-train, ])
boston.test <- Boston[-train, "medv"]
plot(yhat, boston.test)
abline(1,0)
mean((yhat - boston.test)^2)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(randomForest)
set.seed(1)
bag.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 12, importance = TRUE)
bag.boston
?randomForest()
yhat.bag <- predict(bag.boston, newdata = Boston[-train, ])
plot(yhat.bag, boston.test)
abline(0,1)
mean((yhat.bag - boston.test)^2)
yhat.bag <- predict(bag.boston, newdata = Boston[-train, ])
plot(yhat.bag, boston.test)
abline(0,1)
mean((yhat.bag - boston.test)^2)
bag.boston <- randomforest(medv ~ ., data = Boston, subset = train, mtry = 12, ntree = 25)
yhat.bag <- predict(bag.boston, newdata = Boston[-train, ])
plot(yhat.bag, boston.test)
abline(0,1)
mean((yhat.bag - boston.test)^2)
bag.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 12, ntree = 25)
yhat.bag <- predict(bag.boston, newdata = Boston[-train, ])
mean((yhat.bag - boston.test)^2)
#Using the Random Forest method
set.seed(1)
rf.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 6, importance = TRUE)
yhat.rf <- predict(rf.boston, newdata = Boston[-train, ])
mean((yhat.rf - boston.test)^2)
importance(rf.boston)
importance(rf.boston)
#Plot the importance measures
varImpPlot(rf.boston)
#| include: false
#Load libraries for problem set.
library(ISLR2)
library(tree)
library(randomForest)
#Preview dataset
str(Carseats)
1:nrow(Carseats)
set.seed(1)
train <- sample(1:nrow(Carseats), nrow(Carseats)/2)
set.seed(1)
train <- sample(1:nrow(Carseats), nrow(Carseats)/2)
Carseats_test <- Carseats[-train, ]
View(train)
view(Carseats_test)
View(Carseats_test)
View(Carseats[train,])
Carseats_tree <- tree(Sales ~ ., data = Carseats, subset = train)
summary(Carseats_tree)
Carseats_tree <- tree(Sales ~ ., data = Carseats, subset = train)
summary(Carseats_tree)
plot(Carseats_tree)
Carseats_tree <- tree(Sales ~ ., data = Carseats, subset = train)
summary(Carseats_tree)
plot(Carseats_tree)
text(Carseats_tree)
Carseats_tree <- tree(Sales ~ ., data = Carseats, subset = train)
summary(Carseats_tree)
plot(Carseats_tree)
text(Carseats_tree, pretty = 0)
