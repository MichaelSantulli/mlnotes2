Direction ~ Lag2 + Volume,
data = Weekly_Train
)
summary(lda.fit)
#Predict the outcome on the test data
lda.pred <- predict(lda.fit, Weekly_Test)
lda.class <- lda.pred$class
lda.matrix <- table(lda.class, Weekly_Test$Direction)
lda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- lda.matrix[2,1]/(lda.matrix[1,1]+lda.matrix[2,1])
false_neg <- lda.matrix[1,2]/(lda.matrix[1,2]+lda.matrix[2,2])
error_rate <- (lda.matrix[2,1]+lda.matrix[1,2])/length(Weekly_Test$Direction)
#Create a new quadratic discriminant analysis (QDA) model
qda.fit <- qda(
Direction ~ Lag2 + I(Lag2^2),
data = Weekly_Train
)
summary(qda.fit)
#Predict the outcome on the test data
qda.pred <- predict(qda.fit, Weekly_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Weekly_Test$Direction)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Weekly_Test$Direction)
#Create a new quadratic discriminant analysis (QDA) model
qda.fit <- qda(
Direction ~ Lag2*Volume,
data = Weekly_Train
)
summary(qda.fit)
#Predict the outcome on the test data
qda.pred <- predict(qda.fit, Weekly_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Weekly_Test$Direction)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Weekly_Test$Direction)
knn.pred <- knn(train.X, test.X, train.Direction, k = 3)
knn.matrix <- table(knn.pred, Weekly_Test$Direction)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Weekly_Test$Direction)
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Weekly_Test$Direction)
#Preview the dataset
glimpse(Auto)
#Calculate median MPG
mpg_median <- median(Auto$mpg)
#Create new column to show if mpg is greater or less than median
mpg_01 <- rep(0,length(Auto$mpg))
mpg_01[Auto$mpg > mpg_median] = 1
#Add new column to Auto dataset
Auto2 <- cbind(mpg_01,Auto)
pairs(Auto2)
#I didn't want to split the dataset by any of the existing variables since it seemed like they should be distributed randomly in both train and test, so I took the following approach:
#Create a vector of random numbers between 0 and 1
set.seed(1)
random <- runif(length(Auto2$mpg_01),0,1)
#Add the new column to the dataset so every observation has a random number
Auto2 <- cbind(Auto2, random)
#Split the dataset based on the random number values
Auto2_Train <- subset(Auto2, random < 0.5)
Auto2_Test  <- subset(Auto2, random >= 0.5)
lda.fit <- lda(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
lda.pred <- predict(lda.fit, Auto2_Test)
lda.class <- lda.pred$class
lda.matrix <- table(lda.class, Auto2_Test$mpg_01)
lda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- lda.matrix[2,1]/(lda.matrix[1,1]+lda.matrix[2,1])
false_neg <- lda.matrix[1,2]/(lda.matrix[1,2]+lda.matrix[2,2])
error_rate <- (lda.matrix[2,1]+lda.matrix[1,2])/length(Auto2_Test$mpg_01)
qda.fit <- qda(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
qda.pred <- predict(qda.fit, Auto2_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Auto2_Test$mpg_01)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Auto2_Test$mpg_01)
glm.fit <- glm(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train,
family = binomial
)
glm.probs <- predict(glm.fit, Auto2_Test, type = "response")
glm.pred <- rep(0,length(Auto2_Test$mpg_01))
glm.pred[glm.probs > .5] = 1
glm.matrix <- table(glm.pred, Auto2_Test$mpg_01)
glm.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- glm.matrix[2,1]/(glm.matrix[1,1]+glm.matrix[2,1])
false_neg <- glm.matrix[1,2]/(glm.matrix[1,2]+glm.matrix[2,2])
error_rate <- (glm.matrix[2,1]+glm.matrix[1,2])/length(Auto2_Test$mpg_01)
nb.fit <- naiveBayes(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
nb.class <- predict(nb.fit, Auto2_Test)
nb.matrix <- table(nb.class, Auto2_Test$mpg_01)
nb.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- nb.matrix[2,1]/(nb.matrix[1,1]+nb.matrix[2,1])
false_neg <- nb.matrix[1,2]/(nb.matrix[1,2]+nb.matrix[2,2])
error_rate <- (nb.matrix[2,1]+nb.matrix[1,2])/length(Auto2_Test$mpg_01)
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 1)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
#Rerun KNN with K = 2
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 2)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
#Rerun KNN with K = 3
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 3)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
#| include: false
#Load libraries for problem set.
library(ISLR2)
library(MASS)
library(class)
library(e1071)
library(tidyverse)
#View variables in the Weekly dataset
glimpse(Weekly)
#View summary statistics for each variable
summary(Weekly)
#
#pairs(Weekly)
#Construct a logistic regression model
glm.fit <- glm(
Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Weekly,
family = binomial
)
summary(glm.fit)
attach(Weekly)
#Calculate probabilities
glm.probs <- predict(glm.fit, type = "response")
#Create a vector of predictions (preset to value of Down) with same number of observations as Direction
glm.pred <- rep("Down",length(Weekly$Direction))
#Set prediction values to Up where proability is greater than 0.5
glm.pred[glm.probs > 0.5] = "Up"
#Create a confusion matrix of the predictions and actual values of Direction
glm.matrix <- table(glm.pred, Direction)
glm.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- glm.matrix[2,1]/(glm.matrix[1,1]+glm.matrix[2,1])
false_neg <- glm.matrix[1,2]/(glm.matrix[1,2]+glm.matrix[2,2])
error_rate <- (glm.matrix[2,1]+glm.matrix[1,2])/length(Direction)
#Specify training criteria: years 2008 and earlier
train <- Year <= 2008
#Create training dataset (1990 - 2008)
Weekly_Train <- Weekly[train,]
#Create test dataset (2009-2010)
Weekly_Test <- Weekly[!train,]
#Create new logistic regression model
glm.fit2 <- glm(
Direction ~ Lag2,
data = Weekly_Train,
family = binomial
)
summary(glm.fit2)
#Predict the outcome on the test data
glm.probs2 <- predict(glm.fit2, Weekly_Test, type = "response")
glm.pred2 <- rep("Down", length(Weekly_Test$Direction))
glm.pred2[glm.probs2 > .5] = "Up"
glm.matrix2 <- table(glm.pred2, Weekly_Test$Direction)
glm.matrix2
#Calculate false positive, false negative, and total error rates
false_pos <- glm.matrix2[2,1]/(glm.matrix2[1,1]+glm.matrix2[2,1])
false_neg <- glm.matrix2[1,2]/(glm.matrix2[1,2]+glm.matrix2[2,2])
error_rate <- (glm.matrix2[2,1]+glm.matrix2[1,2])/length(Weekly_Test$Direction)
#Create linear discriminant analysis (LDA) model
lda.fit <- lda(
Direction ~ Lag2,
data = Weekly_Train
)
summary(lda.fit)
#Predict the outcome on the test data
lda.pred <- predict(lda.fit, Weekly_Test)
lda.class <- lda.pred$class
lda.matrix <- table(lda.class, Weekly_Test$Direction)
lda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- lda.matrix[2,1]/(lda.matrix[1,1]+lda.matrix[2,1])
false_neg <- lda.matrix[1,2]/(lda.matrix[1,2]+lda.matrix[2,2])
error_rate <- (lda.matrix[2,1]+lda.matrix[1,2])/length(Weekly_Test$Direction)
#Create quadratic discriminant analysis (QDA) model
qda.fit <- qda(
Direction ~ Lag2,
data = Weekly_Train
)
summary(qda.fit)
#Predict the outcome on the test data
qda.pred <- predict(qda.fit, Weekly_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Weekly_Test$Direction)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Weekly_Test$Direction)
#Create parameters for the knn() function
#Training data predictors
train.X <- cbind(Lag1, Lag2)[train,]
#train.X <- Lag2[train]
#Test data predictors
test.X <- cbind(Lag1, Lag2)[!train,]
#test.X <- Lag2[!train]
#Training data outcomes
train.Direction <- Direction[train]
#Set random seed for reproduceability
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k = 1)
knn.matrix <- table(knn.pred, Weekly_Test$Direction)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Weekly_Test$Direction)
nb.fit <- naiveBayes(
Direction ~ Lag2,
data = Weekly_Train
)
summary(nb.fit)
nb.class <- predict(nb.fit, Weekly_Test)
nb.matrix <- table(nb.class, Weekly_Test$Direction)
nb.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- nb.matrix[2,1]/(nb.matrix[1,1]+nb.matrix[2,1])
false_neg <- nb.matrix[1,2]/(nb.matrix[1,2]+nb.matrix[2,2])
error_rate <- (nb.matrix[2,1]+nb.matrix[1,2])/length(Weekly_Test$Direction)
#Create new logistic regression model with an interaction term between Lag 2 and Volume
glm.fit <- glm(
Direction ~ Lag2*Volume,
data = Weekly_Train,
family = binomial
)
summary(glm.fit)
#Predict the outcome on the test data
glm.probs <- predict(glm.fit, Weekly_Test, type = "response")
glm.pred <- rep("Down", length(Weekly_Test$Direction))
glm.pred[glm.probs2 > .5] = "Up"
glm.matrix <- table(glm.pred, Weekly_Test$Direction)
glm.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- glm.matrix[2,1]/(glm.matrix[1,1]+glm.matrix[2,1])
false_neg <- glm.matrix[1,2]/(glm.matrix[1,2]+glm.matrix[2,2])
error_rate <- (glm.matrix[2,1]+glm.matrix[1,2])/length(Weekly_Test$Direction)
#Create new linear discriminant analysis (LDA) model
lda.fit <- lda(
Direction ~ Lag2 + Volume,
data = Weekly_Train
)
summary(lda.fit)
#Predict the outcome on the test data
lda.pred <- predict(lda.fit, Weekly_Test)
lda.class <- lda.pred$class
lda.matrix <- table(lda.class, Weekly_Test$Direction)
lda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- lda.matrix[2,1]/(lda.matrix[1,1]+lda.matrix[2,1])
false_neg <- lda.matrix[1,2]/(lda.matrix[1,2]+lda.matrix[2,2])
error_rate <- (lda.matrix[2,1]+lda.matrix[1,2])/length(Weekly_Test$Direction)
#Create a new quadratic discriminant analysis (QDA) model
qda.fit <- qda(
Direction ~ Lag2 + I(Lag2^2),
data = Weekly_Train
)
summary(qda.fit)
#Predict the outcome on the test data
qda.pred <- predict(qda.fit, Weekly_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Weekly_Test$Direction)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Weekly_Test$Direction)
#Create a new quadratic discriminant analysis (QDA) model
qda.fit <- qda(
Direction ~ Lag2*Volume,
data = Weekly_Train
)
summary(qda.fit)
#Predict the outcome on the test data
qda.pred <- predict(qda.fit, Weekly_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Weekly_Test$Direction)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Weekly_Test$Direction)
knn.pred <- knn(train.X, test.X, train.Direction, k = 3)
knn.matrix <- table(knn.pred, Weekly_Test$Direction)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Weekly_Test$Direction)
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Weekly_Test$Direction)
#Preview the dataset
glimpse(Auto)
#Calculate median MPG
mpg_median <- median(Auto$mpg)
#Create new column to show if mpg is greater or less than median
mpg_01 <- rep(0,length(Auto$mpg))
mpg_01[Auto$mpg > mpg_median] = 1
#Add new column to Auto dataset
Auto2 <- cbind(mpg_01,Auto)
pairs(Auto2)
#I didn't want to split the dataset by any of the existing variables since it seemed like they should be distributed randomly in both train and test, so I took the following approach:
#Create a vector of random numbers between 0 and 1
set.seed(1)
random <- runif(length(Auto2$mpg_01),0,1)
#Add the new column to the dataset so every observation has a random number
Auto2 <- cbind(Auto2, random)
#Split the dataset based on the random number values
Auto2_Train <- subset(Auto2, random < 0.5)
Auto2_Test  <- subset(Auto2, random >= 0.5)
lda.fit <- lda(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
lda.pred <- predict(lda.fit, Auto2_Test)
lda.class <- lda.pred$class
lda.matrix <- table(lda.class, Auto2_Test$mpg_01)
lda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- lda.matrix[2,1]/(lda.matrix[1,1]+lda.matrix[2,1])
false_neg <- lda.matrix[1,2]/(lda.matrix[1,2]+lda.matrix[2,2])
error_rate <- (lda.matrix[2,1]+lda.matrix[1,2])/length(Auto2_Test$mpg_01)
qda.fit <- qda(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
qda.pred <- predict(qda.fit, Auto2_Test)
qda.class <- qda.pred$class
qda.matrix <- table(qda.class, Auto2_Test$mpg_01)
qda.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- qda.matrix[2,1]/(qda.matrix[1,1]+qda.matrix[2,1])
false_neg <- qda.matrix[1,2]/(qda.matrix[1,2]+qda.matrix[2,2])
error_rate <- (qda.matrix[2,1]+qda.matrix[1,2])/length(Auto2_Test$mpg_01)
glm.fit <- glm(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train,
family = binomial
)
glm.probs <- predict(glm.fit, Auto2_Test, type = "response")
glm.pred <- rep(0,length(Auto2_Test$mpg_01))
glm.pred[glm.probs > .5] = 1
glm.matrix <- table(glm.pred, Auto2_Test$mpg_01)
glm.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- glm.matrix[2,1]/(glm.matrix[1,1]+glm.matrix[2,1])
false_neg <- glm.matrix[1,2]/(glm.matrix[1,2]+glm.matrix[2,2])
error_rate <- (glm.matrix[2,1]+glm.matrix[1,2])/length(Auto2_Test$mpg_01)
nb.fit <- naiveBayes(
mpg_01 ~ horsepower + weight + acceleration,
data = Auto2_Train
)
nb.class <- predict(nb.fit, Auto2_Test)
nb.matrix <- table(nb.class, Auto2_Test$mpg_01)
nb.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- nb.matrix[2,1]/(nb.matrix[1,1]+nb.matrix[2,1])
false_neg <- nb.matrix[1,2]/(nb.matrix[1,2]+nb.matrix[2,2])
error_rate <- (nb.matrix[2,1]+nb.matrix[1,2])/length(Auto2_Test$mpg_01)
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 1)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
#Rerun KNN with K = 2
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 2)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
#Rerun KNN with K = 3
#Create new training and test datasets keeping only the columns needed for prediction
train.X <- subset(Auto2_Train, select = c(horsepower, weight, acceleration))
test.X <- subset(Auto2_Test, select = c(horsepower, weight, acceleration))
knn.pred <- knn(train.X, test.X, Auto2_Train$mpg_01, k = 3)
knn.matrix <- table(knn.pred, Auto2_Test$mpg_01)
knn.matrix
#Calculate false positive, false negative, and total error rates
false_pos <- knn.matrix[2,1]/(knn.matrix[1,1]+knn.matrix[2,1])
false_neg <- knn.matrix[1,2]/(knn.matrix[1,2]+knn.matrix[2,2])
error_rate <- (knn.matrix[2,1]+knn.matrix[1,2])/length(Auto2_Train$mpg_01)
2^100
I(2^100)
?I
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
view(train)
View(train)
library(tidyverse)
view(train)
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
#Calculate the test MSE
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
#Calculate the test MSE
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#Fit a quadratic and cubic model with the poly() function
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg- predict(lm.fit2, Auto))[-train]^2)
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
#Calculate the test MSE
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#Fit a quadratic and cubic model with the poly() function
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg- predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg- predict(lm.fit2, Auto))[-train]^2)
library(ISLR2)
set.seed(1)
#Split data in two for training and testing
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
#Calculate the test MSE
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#Fit a quadratic and cubic model with the poly() function
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg- predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg- predict(lm.fit3, Auto))[-train]^2)
?sample
